{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Segregation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Parquet Hadoop File Format from HDFS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---------+-------+-----------+-------+----+---------+-----+-----------+--------+--------+--------+-----------+---+\n",
      "|age|      job|marital|  education|housing|loan|  contact|month|day_of_week|duration|campaign|previous|   poutcome|  y|\n",
      "+---+---------+-------+-----------+-------+----+---------+-----+-----------+--------+--------+--------+-----------+---+\n",
      "| 56|housemaid|married|   basic.4y|     no|  no|telephone|  may|        mon|     261|       1|       0|nonexistent| no|\n",
      "| 57| services|married|high.school|     no|  no|telephone|  may|        mon|     149|       1|       0|nonexistent| no|\n",
      "| 37| services|married|high.school|    yes|  no|telephone|  may|        mon|     226|       1|       0|nonexistent| no|\n",
      "| 40|   admin.|married|   basic.6y|     no|  no|telephone|  may|        mon|     151|       1|       0|nonexistent| no|\n",
      "| 56| services|married|high.school|     no| yes|telephone|  may|        mon|     307|       1|       0|nonexistent| no|\n",
      "+---+---------+-------+-----------+-------+----+---------+-----+-----------+--------+--------+--------+-----------+---+\n",
      "only showing top 5 rows\n",
      "\n",
      "root\n",
      " |-- age: integer (nullable = true)\n",
      " |-- job: string (nullable = true)\n",
      " |-- marital: string (nullable = true)\n",
      " |-- education: string (nullable = true)\n",
      " |-- housing: string (nullable = true)\n",
      " |-- loan: string (nullable = true)\n",
      " |-- contact: string (nullable = true)\n",
      " |-- month: string (nullable = true)\n",
      " |-- day_of_week: string (nullable = true)\n",
      " |-- duration: integer (nullable = true)\n",
      " |-- campaign: integer (nullable = true)\n",
      " |-- previous: integer (nullable = true)\n",
      " |-- poutcome: string (nullable = true)\n",
      " |-- y: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# load parquet hadoop file format from hdfs\n",
    "\n",
    "df = spark.read.parquet(\"hdfs://localhost:9820/in_proyek2/bank-additional.parq\")\n",
    "#df = spark.read.parquet(\"bank-additional.parq\")\n",
    "df.show(5)\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- age: integer (nullable = true)\n",
      " |-- job: string (nullable = true)\n",
      " |-- marital: string (nullable = true)\n",
      " |-- education: string (nullable = true)\n",
      " |-- housing: string (nullable = true)\n",
      " |-- loan: string (nullable = true)\n",
      " |-- month: string (nullable = true)\n",
      " |-- day_of_week: string (nullable = true)\n",
      " |-- duration: integer (nullable = true)\n",
      " |-- campaign: integer (nullable = true)\n",
      " |-- previous: integer (nullable = true)\n",
      " |-- poutcome: string (nullable = true)\n",
      " |-- y: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = df.select('age', 'job', 'marital', 'education', 'housing', 'loan', 'month', 'day_of_week', 'duration', 'campaign', 'previous', 'poutcome', 'y')\n",
    "cols = df.columns\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.sql.functions import mean, col, split, col, regexp_extract, when, lit\n",
    "from pyspark.ml.feature import StringIndexer, IndexToString, VectorAssembler, VectorIndexer\n",
    "from pyspark.ml.feature import QuantileDiscretizer, OneHotEncoder, OneHotEncoder\n",
    "\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "\n",
    "from pyspark.ml.classification import LogisticRegression, DecisionTreeClassifier, RandomForestClassifier\n",
    "\n",
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- age: integer (nullable = true)\n",
      " |-- job: string (nullable = true)\n",
      " |-- marital: string (nullable = true)\n",
      " |-- education: string (nullable = true)\n",
      " |-- housing: string (nullable = true)\n",
      " |-- loan: string (nullable = true)\n",
      " |-- month: string (nullable = true)\n",
      " |-- day_of_week: string (nullable = true)\n",
      " |-- duration: integer (nullable = true)\n",
      " |-- campaign: integer (nullable = true)\n",
      " |-- previous: integer (nullable = true)\n",
      " |-- poutcome: string (nullable = true)\n",
      " |-- y: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Dataset Count: 28721\n",
      "Test Dataset Count: 12445\n"
     ]
    }
   ],
   "source": [
    "(trainingData, testData) = df.randomSplit([0.7, 0.3], seed=10)\n",
    "print(\"Training Dataset Count: \" + str(trainingData.count()))\n",
    "print(\"Test Dataset Count: \" + str(testData.count()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The first 5 samples of the Training Dataset:\n",
      "+---+-------+-------+-----------+-------+----+-----+-----------+--------+--------+--------+-----------+---+\n",
      "|age|job    |marital|education  |housing|loan|month|day_of_week|duration|campaign|previous|poutcome   |y  |\n",
      "+---+-------+-------+-----------+-------+----+-----+-----------+--------+--------+--------+-----------+---+\n",
      "|17 |student|single |basic.9y   |yes    |no  |aug  |fri        |92      |3       |2       |success    |no |\n",
      "|17 |student|single |basic.9y   |yes    |yes |aug  |fri        |498     |2       |1       |failure    |yes|\n",
      "|17 |student|single |unknown    |yes    |no  |aug  |wed        |432     |3       |2       |success    |no |\n",
      "|18 |student|single |basic.4y   |no     |no  |apr  |thu        |108     |1       |0       |nonexistent|no |\n",
      "|18 |student|single |high.school|no     |no  |may  |fri        |271     |1       |1       |failure    |yes|\n",
      "+---+-------+-------+-----------+-------+----+-----+-----------+--------+--------+--------+-----------+---+\n",
      "only showing top 5 rows\n",
      "\n",
      "The first 5 samples of the Test Dataset:\n",
      "+---+-------+-------+---------+-------+----+-----+-----------+--------+--------+--------+-----------+---+\n",
      "|age|job    |marital|education|housing|loan|month|day_of_week|duration|campaign|previous|poutcome   |y  |\n",
      "+---+-------+-------+---------+-------+----+-----+-----------+--------+--------+--------+-----------+---+\n",
      "|17 |student|single |basic.9y |yes    |no  |aug  |fri        |182     |2       |2       |failure    |no |\n",
      "|17 |student|single |unknown  |no     |yes |oct  |tue        |896     |1       |2       |success    |yes|\n",
      "|18 |student|single |basic.4y |yes    |yes |apr  |thu        |184     |2       |0       |nonexistent|no |\n",
      "|18 |student|single |basic.6y |yes    |no  |aug  |mon        |628     |1       |0       |nonexistent|no |\n",
      "|18 |student|single |basic.9y |yes    |no  |aug  |tue        |642     |1       |0       |nonexistent|yes|\n",
      "+---+-------+-------+---------+-------+----+-----+-----------+--------+--------+--------+-----------+---+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"The first 5 samples of the Training Dataset:\")\n",
    "trainingData.show(5, False)\n",
    "print(\"The first 5 samples of the Test Dataset:\")\n",
    "testData.show(5, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dummy(df, categoricalCols, continuousCols, labelCol):\n",
    "  \n",
    "  indexers = [StringIndexer(inputCol=c, outputCol=\"{0}_indexed\".format(c)) for c in categoricalCols]\n",
    "\n",
    "  encoders = [OneHotEncoder(inputCol=indexer.getOutputCol(),\n",
    "                             outputCol=\"{0}_encoded\".format(indexer.getOutputCol()))\n",
    "              for indexer in indexers]\n",
    "\n",
    "  assembler = VectorAssembler(inputCols=[encoder.getOutputCol() for encoder in encoders]\n",
    "                              + continuousCols, outputCol=\"features\")\n",
    "  \n",
    "  indexer = StringIndexer(inputCol=labelCol, outputCol='indexedLabel')\n",
    "\n",
    "  pipeline = Pipeline(stages = indexers + encoders + [assembler] + [indexer])\n",
    "\n",
    "  model=pipeline.fit(df)\n",
    "  data = model.transform(df)\n",
    "\n",
    "  data = data.withColumn('label', col(labelCol))\n",
    "  \n",
    "  return data.select('features', 'indexedLabel', 'label'), StringIndexer(inputCol='label').fit(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lr = LogisticRegression(labelCol=\"indexedLabel\", featuresCol=\"indexedFeatures\") # using this line if you would using indexedFeatures instead features column\n",
    "lr = LogisticRegression(labelCol=\"indexedLabel\", featuresCol=\"features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelConverter = IndexToString(inputCol=\"prediction\", outputCol=\"predictedLabel\", labels=labelindexer.labels) \n",
    "\n",
    "pipeline = Pipeline(stages=[featureIndexer, lr, labelConverter])\n",
    "\n",
    "lrModel = pipeline.fit(trainingData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = lrModel.transform(testData)\n",
    "\n",
    "predictions.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions.select(\"features\", \"label\", \"probability\", \"predictedLabel\").show(5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
