{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .master(\"local[2]\") \\\n",
    "    .appName(\"Load Data From HDFS\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - hive</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://DESKTOP-EICB9IN:4043\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.0.2</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>PySparkShell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x1ece2760c88>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---------+-------+-----------+-------+----+---------+-----+-----------+--------+--------+--------+-----------+---+\n",
      "|age|      job|marital|  education|housing|loan|  contact|month|day_of_week|duration|campaign|previous|   poutcome|  y|\n",
      "+---+---------+-------+-----------+-------+----+---------+-----+-----------+--------+--------+--------+-----------+---+\n",
      "| 56|housemaid|married|   basic.4y|     no|  no|telephone|  may|        mon|     261|       1|       0|nonexistent| no|\n",
      "| 57| services|married|high.school|     no|  no|telephone|  may|        mon|     149|       1|       0|nonexistent| no|\n",
      "| 37| services|married|high.school|    yes|  no|telephone|  may|        mon|     226|       1|       0|nonexistent| no|\n",
      "| 40|   admin.|married|   basic.6y|     no|  no|telephone|  may|        mon|     151|       1|       0|nonexistent| no|\n",
      "| 56| services|married|high.school|     no| yes|telephone|  may|        mon|     307|       1|       0|nonexistent| no|\n",
      "+---+---------+-------+-----------+-------+----+---------+-----+-----------+--------+--------+--------+-----------+---+\n",
      "only showing top 5 rows\n",
      "\n",
      "root\n",
      " |-- age: integer (nullable = true)\n",
      " |-- job: string (nullable = true)\n",
      " |-- marital: string (nullable = true)\n",
      " |-- education: string (nullable = true)\n",
      " |-- housing: string (nullable = true)\n",
      " |-- loan: string (nullable = true)\n",
      " |-- contact: string (nullable = true)\n",
      " |-- month: string (nullable = true)\n",
      " |-- day_of_week: string (nullable = true)\n",
      " |-- duration: integer (nullable = true)\n",
      " |-- campaign: integer (nullable = true)\n",
      " |-- previous: integer (nullable = true)\n",
      " |-- poutcome: string (nullable = true)\n",
      " |-- y: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# load hadoop format file parquet from hdfs\n",
    "\n",
    "bank_df = spark.read.parquet(\"hdfs://localhost:9820/in_proyek2/bank-additional.parq\")\n",
    "#bank_df = spark.read.parquet(\"bank-additional.parq\")\n",
    "bank_df.show(5)\n",
    "bank_df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing needful libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.sql.functions import mean, col, split, col, regexp_extract, when, lit\n",
    "from pyspark.ml.feature import StringIndexer, IndexToString, VectorAssembler, VectorIndexer\n",
    "from pyspark.ml.feature import QuantileDiscretizer, OneHotEncoder\n",
    "\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "\n",
    "from pyspark.ml.classification import LogisticRegression, DecisionTreeClassifier, RandomForestClassifier\n",
    "\n",
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of customers is 41166\n"
     ]
    }
   ],
   "source": [
    "# Number of customers in the dataframe\n",
    "clients_count = bank_df.count()\n",
    "print(\"Number of customers is {}\".format(clients_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+\n",
      "|  y|count|\n",
      "+---+-----+\n",
      "| no|36526|\n",
      "|yes| 4640|\n",
      "+---+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Number of customers which are subscribed vs. those not subscribed a term deposit\n",
    "groupBy_clients = bank_df.groupBy(\"y\").count()\n",
    "groupBy_clients.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+-----------------+-----------------+-------------------+\n",
      "|summary|               age|         duration|         campaign|           previous|\n",
      "+-------+------------------+-----------------+-----------------+-------------------+\n",
      "|  count|             41166|            41166|            41166|              41166|\n",
      "|   mean| 40.02356313462566|258.3929456347471| 2.54875382597289|0.17305543409609872|\n",
      "| stddev|10.421897109457703|259.3029641183626|2.645304359228272|0.49501715074689073|\n",
      "|    min|                17|                0|                1|                  0|\n",
      "|    max|                98|             4918|               32|                  7|\n",
      "+-------+------------------+-----------------+-----------------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "bank_df.describe([t[0] for t in bank_df.dtypes if t[1] == 'int']).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing Data for Machine Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dummy(df, categoricalCols, continuousCols, labelCol):\n",
    "    indexers = [StringIndexer(inputCol=c, outputCol=\"{0}_indexed\".format(c)) for c in categoricalCols]\n",
    "    encoders = [OneHotEncoder(inputCol=indexer.getOutputCol(), outputCol=\"{0}_encoded\".format(indexer.getOutputCol())) for indexer in indexers]\n",
    "    \n",
    "    assembler = VectorAssembler(inputCols=[encoder.getOutputCol() for encoder in encoders] + continuousCols, outputCol=\"features\")\n",
    "    indexer = StringIndexer(inputCol=labelCol, outputCol='indexedLabel')\n",
    "    \n",
    "    pipeline = Pipeline(stages = indexers + encoders + [assembler] + [indexer])\n",
    "    model=pipeline.fit(df)\n",
    "    data = model.transform(df)\n",
    "    \n",
    "    data = data.withColumn('label', col(labelCol))\n",
    "    \n",
    "    return data.select('features', 'indexedLabel', 'label'), StringIndexer(inputCol='label').fit(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------+-----+\n",
      "|            features|indexedLabel|label|\n",
      "+--------------------+------------+-----+\n",
      "|(42,[8,11,18,22,2...|         0.0|   no|\n",
      "|(42,[3,11,15,22,2...|         0.0|   no|\n",
      "|(42,[3,11,15,21,2...|         0.0|   no|\n",
      "|(42,[0,11,19,22,2...|         0.0|   no|\n",
      "|(42,[3,11,15,23,3...|         0.0|   no|\n",
      "+--------------------+------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# transform the data\n",
    "categoricalColumns = ['job', 'marital', 'education', 'housing', 'loan', 'month', 'day_of_week', 'poutcome']\n",
    "numericCols = ['age', 'duration', 'campaign', 'previous']\n",
    "(bank_df, labelindexer) = get_dummy(bank_df, categoricalColumns, numericCols, 'y')\n",
    "bank_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------+-----+--------------------+\n",
      "|            features|indexedLabel|label|     indexedFeatures|\n",
      "+--------------------+------------+-----+--------------------+\n",
      "|(42,[8,11,18,22,2...|         0.0|   no|(42,[8,11,18,22,2...|\n",
      "|(42,[3,11,15,22,2...|         0.0|   no|(42,[3,11,15,22,2...|\n",
      "|(42,[3,11,15,21,2...|         0.0|   no|(42,[3,11,15,21,2...|\n",
      "|(42,[0,11,19,22,2...|         0.0|   no|(42,[0,11,19,22,2...|\n",
      "|(42,[3,11,15,23,3...|         0.0|   no|(42,[3,11,15,23,3...|\n",
      "+--------------------+------------+-----+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# fit the following featureIndexer model on the whole of the bank_df dataframe\n",
    "featureIndexer = VectorIndexer(inputCol=\"features\", outputCol=\"indexedFeatures\", maxCategories=4).fit(bank_df)\n",
    "\n",
    "featureIndexer.transform(bank_df).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------------------------------------------------------------------------+------------+-----+\n",
      "|features                                                                               |indexedLabel|label|\n",
      "+---------------------------------------------------------------------------------------+------------+-----+\n",
      "|(42,[8,11,18,22,23,33,36,38,39,40],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,56.0,261.0,1.0])       |0.0         |no   |\n",
      "|(42,[3,11,15,22,23,33,36,38,39,40],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,57.0,149.0,1.0])       |0.0         |no   |\n",
      "|(42,[3,11,15,21,22,23,33,36,38,39,40],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,37.0,226.0,1.0])|0.0         |no   |\n",
      "|(42,[0,11,19,22,23,33,36,38,39,40],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,40.0,151.0,1.0])       |0.0         |no   |\n",
      "|(42,[3,11,15,23,33,36,38,39,40],[1.0,1.0,1.0,1.0,1.0,1.0,56.0,307.0,1.0])              |0.0         |no   |\n",
      "+---------------------------------------------------------------------------------------+------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "bank_df.show(5, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Dataset Count: 28793\n",
      "Test Dataset Count: 12373\n"
     ]
    }
   ],
   "source": [
    "(trainingData, testData) = bank_df.randomSplit([0.7, 0.3], seed=202105)\n",
    "print(\"Training Dataset Count: \" + str(trainingData.count()))\n",
    "print(\"Test Dataset Count: \" + str(testData.count()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The first 5 samples of the Training Dataset:\n",
      "+---------------------------------------------------------------------------------------+------------+-----+\n",
      "|features                                                                               |indexedLabel|label|\n",
      "+---------------------------------------------------------------------------------------+------------+-----+\n",
      "|(42,[0,11,14,21,22,23,32,36,38,39,40],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,25.0,251.0,4.0])|0.0         |no   |\n",
      "|(42,[0,11,14,21,22,23,32,36,38,39,40],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,29.0,203.0,1.0])|0.0         |no   |\n",
      "|(42,[0,11,14,21,22,23,32,36,38,39,40],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,29.0,302.0,1.0])|0.0         |no   |\n",
      "|(42,[0,11,14,21,22,23,32,36,38,39,40],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,30.0,196.0,2.0])|0.0         |no   |\n",
      "|(42,[0,11,14,21,22,23,32,36,38,39,40],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,31.0,102.0,4.0])|0.0         |no   |\n",
      "+---------------------------------------------------------------------------------------+------------+-----+\n",
      "only showing top 5 rows\n",
      "\n",
      "The first 5 samples of the Test Dataset:\n",
      "+---------------------------------------------------------------------------------------+------------+-----+\n",
      "|features                                                                               |indexedLabel|label|\n",
      "+---------------------------------------------------------------------------------------+------------+-----+\n",
      "|(42,[0,11,14,21,22,23,32,36,38,39,40],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,30.0,911.0,2.0])|1.0         |yes  |\n",
      "|(42,[0,11,14,21,22,23,32,36,38,39,40],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,32.0,70.0,1.0]) |0.0         |no   |\n",
      "|(42,[0,11,14,21,22,23,32,36,38,39,40],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,32.0,71.0,2.0]) |0.0         |no   |\n",
      "|(42,[0,11,14,21,22,23,32,36,38,39,40],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,32.0,151.0,5.0])|0.0         |no   |\n",
      "|(42,[0,11,14,21,22,23,32,36,38,39,40],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,33.0,139.0,2.0])|0.0         |no   |\n",
      "+---------------------------------------------------------------------------------------+------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"The first 5 samples of the Training Dataset:\")\n",
    "trainingData.show(5, False)\n",
    "print(\"The first 5 samples of the Test Dataset:\")\n",
    "testData.show(5, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lr = LogisticRegression(labelCol=\"indexedLabel\", featuresCol=\"indexedFeatures\") # using this line if you would using indexedFeatures instead features column\n",
    "lr = LogisticRegression(labelCol=\"indexedLabel\", featuresCol=\"features\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pipeline Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelConverter = IndexToString(inputCol=\"prediction\", outputCol=\"predictedLabel\", labels=labelindexer.labels) \n",
    "\n",
    "pipeline = Pipeline(stages=[featureIndexer, lr, labelConverter])\n",
    "\n",
    "lrModel = pipeline.fit(trainingData)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------+-----+--------------------+--------------------+--------------------+----------+--------------+\n",
      "|            features|indexedLabel|label|     indexedFeatures|       rawPrediction|         probability|prediction|predictedLabel|\n",
      "+--------------------+------------+-----+--------------------+--------------------+--------------------+----------+--------------+\n",
      "|(42,[0,11,14,21,2...|         1.0|  yes|(42,[0,11,14,21,2...|[0.33983678077516...|[0.58415087448952...|       0.0|            no|\n",
      "|(42,[0,11,14,21,2...|         0.0|   no|(42,[0,11,14,21,2...|[3.85697210202566...|[0.97930542743745...|       0.0|            no|\n",
      "|(42,[0,11,14,21,2...|         0.0|   no|(42,[0,11,14,21,2...|[3.95354789840121...|[0.98117468302368...|       0.0|            no|\n",
      "|(42,[0,11,14,21,2...|         0.0|   no|(42,[0,11,14,21,2...|[3.91146234412612...|[0.98038137615657...|       0.0|            no|\n",
      "|(42,[0,11,14,21,2...|         0.0|   no|(42,[0,11,14,21,2...|[3.65748506266817...|[0.97485145497825...|       0.0|            no|\n",
      "+--------------------+------------+-----+--------------------+--------------------+--------------------+----------+--------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Make predictions on the test data using the transform() method.\n",
    "predictions = lrModel.transform(testData)\n",
    "predictions.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+--------------------+--------------+\n",
      "|            features|label|         probability|predictedLabel|\n",
      "+--------------------+-----+--------------------+--------------+\n",
      "|(42,[0,11,14,21,2...|  yes|[0.58415087448952...|            no|\n",
      "|(42,[0,11,14,21,2...|   no|[0.97930542743745...|            no|\n",
      "|(42,[0,11,14,21,2...|   no|[0.98117468302368...|            no|\n",
      "|(42,[0,11,14,21,2...|   no|[0.98038137615657...|            no|\n",
      "|(42,[0,11,14,21,2...|   no|[0.97485145497825...|            no|\n",
      "+--------------------+-----+--------------------+--------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions.select(\"features\", \"label\", \"probability\", \"predictedLabel\").show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compute the model accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------------+\n",
      "|label|count(label)|\n",
      "+-----+------------+\n",
      "|   no|       10990|\n",
      "|  yes|        1383|\n",
      "+-----+------------+\n",
      "\n",
      "+--------------+---------------------+\n",
      "|predictedLabel|count(predictedLabel)|\n",
      "+--------------+---------------------+\n",
      "|            no|                11631|\n",
      "|           yes|                  742|\n",
      "+--------------+---------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cm = predictions.select(\"label\", \"predictedLabel\")          \n",
    "cm.groupby('label').agg({'label': 'count'}).show()  \n",
    "cm.groupby('predictedLabel').agg({'predictedLabel': 'count'}).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------+-----+\n",
      "|label|predictedLabel|count|\n",
      "+-----+--------------+-----+\n",
      "|   no|            no|10723|\n",
      "|   no|           yes|  267|\n",
      "|  yes|           yes|  475|\n",
      "|  yes|            no|  908|\n",
      "+-----+--------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions.groupBy('label', 'predictedLabel').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Accuracy for test set is 0.9050351571971228\n"
     ]
    }
   ],
   "source": [
    "print(\"The Accuracy for test set is {}\".format(cm.filter(cm.label == cm.predictedLabel).count()/cm.count()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Accuracy for test set is 0.9050351571971228\n"
     ]
    }
   ],
   "source": [
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"indexedLabel\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "print(\"The Accuracy for test set is {}\".format(evaluator.evaluate(predictions)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
